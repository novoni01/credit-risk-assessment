{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edacb7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "#gather data from a specific csv file and return as a pandas df\n",
    "BASE = Path.cwd()\n",
    "DATA = BASE / \"training_data\"\n",
    "#Make sure training_data folder exists\n",
    "DATA.mkdir(parents= True, exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5236b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the user path \n",
    "user_path = os.path.expanduser(\"~\")\n",
    "#Make the path to the kaggle json\n",
    "downloads_path = os.path.join(user_path, 'Downloads/kaggle.json')\n",
    "\n",
    "#Make the .kaggle folder in user\n",
    "kaggle_folder = os.path.join(user_path, \".kaggle\")\n",
    "os.makedirs(kaggle_folder, exist_ok= True)\n",
    "\n",
    "print(os.path.exists(downloads_path))\n",
    "\n",
    "if os.path.exists(downloads_path):\n",
    "    try:\n",
    "        print(\"moving kaggle.json to user\")\n",
    "        #Make .kaggle folder path and check it exists\n",
    "        \n",
    "        #Move json to the folder\n",
    "        shutil.move(downloads_path, kaggle_folder)\n",
    "    except Exception as e:\n",
    "        print(f\"Error when trying to move kaggle.json: {e}\")\n",
    "else:\n",
    "    #attempt to check if kaggle.json already exists\n",
    "    final = os.path.join(kaggle_folder, \"kaggle.json\")\n",
    "    if os.path.exists(final):\n",
    "        print(\"kaggle json already exists in user\")\n",
    "    else:\n",
    "        print(\"please download kaggle.json\")\n",
    "\n",
    "#print(\"Successfully moved json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cad2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO USE THIS API you must have a .kaggle folder in your 'C:\\NAME' directory -> then paste the kaggle.json authenticator\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "print(api.dataset_list_files('wordsforthewise/lending-club').files)\n",
    "\n",
    "api.dataset_download_files('wordsforthewise/lending-club', path= DATA, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "033e611c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WindowsPath('c:/Users/Saul/Desktop/Credit Risk Assessment/credit-risk-assessment/ETL/training_data/accepted_2007_to_2018q4.csv'), WindowsPath('c:/Users/Saul/Desktop/Credit Risk Assessment/credit-risk-assessment/ETL/training_data/rejected_2007_to_2018q4.csv'), WindowsPath('c:/Users/Saul/Desktop/Credit Risk Assessment/credit-risk-assessment/ETL/training_data/accepted_2007_to_2018q4.csv/accepted_2007_to_2018Q4.csv'), WindowsPath('c:/Users/Saul/Desktop/Credit Risk Assessment/credit-risk-assessment/ETL/training_data/rejected_2007_to_2018q4.csv/rejected_2007_to_2018Q4.csv')]\n",
      "c:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\ETL\\training_data\\accepted_2007_to_2018q4.csv is folder or dir\n",
      "c:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\ETL\\training_data\\rejected_2007_to_2018q4.csv is folder or dir\n",
      "c:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\ETL\\training_data\\accepted_2007_to_2018q4.csv\\accepted_2007_to_2018Q4.csv is a file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saul\\AppData\\Local\\Temp\\ipykernel_4384\\3710330960.py:11: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return_list.append(pd.read_csv(item))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\ETL\\training_data\\rejected_2007_to_2018q4.csv\\rejected_2007_to_2018Q4.csv is a file\n"
     ]
    }
   ],
   "source": [
    "def retrieve_training_csv(): \n",
    "    \"\"\" Function that returns all the csv files in the training data folder as a dataframe object \"\"\" \n",
    "    csv_list = list(DATA.glob(\"**/*.csv\")) \n",
    "    return_list = [] \n",
    "    print(csv_list)\n",
    "\n",
    "    #traverse each item inthe data path, and if a file ending in .csv is found, turn it into a df and append to return list \n",
    "    for item in csv_list: \n",
    "        if os.path.isfile(item): \n",
    "            print(f\"{item} is a file\") \n",
    "            return_list.append(pd.read_csv(item)) \n",
    "        else: print(f\"{item} is folder or dir\")\n",
    "\n",
    "    if return_list: \n",
    "        return return_list \n",
    "    else: \n",
    "        print(f\"No csv files found in {DATA}\") \n",
    "        return []\n",
    "\n",
    "def get_dir_size(path): \n",
    "    \"\"\" Get directory size in MBs \"\"\" \n",
    "    total = 0 \n",
    "    for dirpath, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            file_path = os.path.join(dirpath, f)\n",
    "            \n",
    "            try:\n",
    "                total += os.path.getsize(file_path) \n",
    "                print(f\"{total/1000000} MB\")\n",
    "            except: \n",
    "                continue \n",
    "        return total/1000000\n",
    "    \n",
    "def delete_large_files(): \n",
    "    \"\"\" Function that deletes the large files downloaded from kaggle to save space \n",
    "    Deletes files to prevent any storage errors when pushing code to github \"\"\"\n",
    "\n",
    "    for paths in DATA.glob(\"**/*\"): \n",
    "        if os.path.isdir(paths): \n",
    "            try:\n",
    "                size = get_dir_size(paths) \n",
    "                print(f\"size of {paths} is {size}\")\n",
    "\n",
    "                if size > 100: \n",
    "                    print(f\"deleting {paths}\") \n",
    "                    shutil.rmtree(paths) \n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error when trying to get size or delete file: {e}\")\n",
    "        else:\n",
    "            if paths.suffix == \".gz\":\n",
    "                os.remove(paths)\n",
    "                #print(paths)\n",
    "        \n",
    "\n",
    "df_list = retrieve_training_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26a40853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create different pointers to the csvs in the list for easier access\n",
    "raw_accepted_loans = df_list[0].copy()\n",
    "raw_rejected_loans = df_list[1].copy()\n",
    "#@raw_loans_paid_info = df_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1390ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount Requested</th>\n",
       "      <th>Application Date</th>\n",
       "      <th>Loan Title</th>\n",
       "      <th>Risk_Score</th>\n",
       "      <th>Debt-To-Income Ratio</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>State</th>\n",
       "      <th>Employment Length</th>\n",
       "      <th>Policy Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2007-05-26</td>\n",
       "      <td>Wedding Covered but No Honeymoon</td>\n",
       "      <td>693.0</td>\n",
       "      <td>10%</td>\n",
       "      <td>481xx</td>\n",
       "      <td>NM</td>\n",
       "      <td>4 years</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000.0</td>\n",
       "      <td>2007-05-26</td>\n",
       "      <td>Consolidating Debt</td>\n",
       "      <td>703.0</td>\n",
       "      <td>10%</td>\n",
       "      <td>010xx</td>\n",
       "      <td>MA</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>2007-05-27</td>\n",
       "      <td>Want to consolidate my debt</td>\n",
       "      <td>715.0</td>\n",
       "      <td>10%</td>\n",
       "      <td>212xx</td>\n",
       "      <td>MD</td>\n",
       "      <td>1 year</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>2007-05-27</td>\n",
       "      <td>waksman</td>\n",
       "      <td>698.0</td>\n",
       "      <td>38.64%</td>\n",
       "      <td>017xx</td>\n",
       "      <td>MA</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500.0</td>\n",
       "      <td>2007-05-27</td>\n",
       "      <td>mdrigo</td>\n",
       "      <td>509.0</td>\n",
       "      <td>9.43%</td>\n",
       "      <td>209xx</td>\n",
       "      <td>MD</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15000.0</td>\n",
       "      <td>2007-05-27</td>\n",
       "      <td>Trinfiniti</td>\n",
       "      <td>645.0</td>\n",
       "      <td>0%</td>\n",
       "      <td>105xx</td>\n",
       "      <td>NY</td>\n",
       "      <td>3 years</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>2007-05-27</td>\n",
       "      <td>NOTIFYi Inc</td>\n",
       "      <td>693.0</td>\n",
       "      <td>10%</td>\n",
       "      <td>210xx</td>\n",
       "      <td>MD</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3900.0</td>\n",
       "      <td>2007-05-27</td>\n",
       "      <td>For Justin.</td>\n",
       "      <td>700.0</td>\n",
       "      <td>10%</td>\n",
       "      <td>469xx</td>\n",
       "      <td>IN</td>\n",
       "      <td>2 years</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>2007-05-28</td>\n",
       "      <td>title?</td>\n",
       "      <td>694.0</td>\n",
       "      <td>10%</td>\n",
       "      <td>808xx</td>\n",
       "      <td>CO</td>\n",
       "      <td>4 years</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2500.0</td>\n",
       "      <td>2007-05-28</td>\n",
       "      <td>timgerst</td>\n",
       "      <td>573.0</td>\n",
       "      <td>11.76%</td>\n",
       "      <td>407xx</td>\n",
       "      <td>KY</td>\n",
       "      <td>4 years</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount Requested Application Date                        Loan Title  \\\n",
       "0            1000.0       2007-05-26  Wedding Covered but No Honeymoon   \n",
       "1            1000.0       2007-05-26                Consolidating Debt   \n",
       "2           11000.0       2007-05-27       Want to consolidate my debt   \n",
       "3            6000.0       2007-05-27                           waksman   \n",
       "4            1500.0       2007-05-27                            mdrigo   \n",
       "5           15000.0       2007-05-27                        Trinfiniti   \n",
       "6           10000.0       2007-05-27                       NOTIFYi Inc   \n",
       "7            3900.0       2007-05-27                       For Justin.   \n",
       "8            3000.0       2007-05-28                            title?   \n",
       "9            2500.0       2007-05-28                          timgerst   \n",
       "\n",
       "   Risk_Score Debt-To-Income Ratio Zip Code State Employment Length  \\\n",
       "0       693.0                  10%    481xx    NM           4 years   \n",
       "1       703.0                  10%    010xx    MA          < 1 year   \n",
       "2       715.0                  10%    212xx    MD            1 year   \n",
       "3       698.0               38.64%    017xx    MA          < 1 year   \n",
       "4       509.0                9.43%    209xx    MD          < 1 year   \n",
       "5       645.0                   0%    105xx    NY           3 years   \n",
       "6       693.0                  10%    210xx    MD          < 1 year   \n",
       "7       700.0                  10%    469xx    IN           2 years   \n",
       "8       694.0                  10%    808xx    CO           4 years   \n",
       "9       573.0               11.76%    407xx    KY           4 years   \n",
       "\n",
       "   Policy Code  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "5          0.0  \n",
       "6          0.0  \n",
       "7          0.0  \n",
       "8          0.0  \n",
       "9          0.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rejected_loans.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5177324b",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_columns = list(raw_accepted_loans.columns)\n",
    "print(al_columns)\n",
    "raw_accepted_loans['loan_status'].head(10)\n",
    "num_cols = [\n",
    "    \"id\", \"loan_amnt\", \"funded_amnt\", \"term\", \"int_rate\", \"installment\", \"annual_inc\",\n",
    "    \"dti\", \"delinq_2yrs\", \"fico_range_low\", \"fico_range_high\", \"inq_last_6mths\",\n",
    "    \"open_acc\", \"revol_bal\", \"revol_util\", \"total_acc\", \"pub_rec_bankruptcies\"\n",
    "]\n",
    "\n",
    "text_cols = [\n",
    "    \"home_ownership\", \"loan_status\", \"purpose\", \"application_type\", \"verification_status\"\n",
    "]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "raw_specific_al = raw_accepted_loans[target_columns]\n",
    "raw_specific_al.head(10).T\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d336486",
   "metadata": {},
   "source": [
    "**Clean Accepted Loans Data**\n",
    "- Provide a data summary\n",
    "- Standardize all data in the columns to reasonable types (ex: object -> float)\n",
    "- Clean up any bad data (missing values, duplicates, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bab88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only find columns with valid ids (not string or empty)\n",
    "cleaned_accepted_loans = raw_accepted_loans[num_cols + text_cols].copy()\n",
    "cleaned_accepted_loans = cleaned_accepted_loans[pd.to_numeric(cleaned_accepted_loans['id'], errors='coerce').notna()]\n",
    "\n",
    "#convert id column to int instead of obj\n",
    "cleaned_accepted_loans['id'] = cleaned_accepted_loans['id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the the term column to make it float (and in months)\n",
    "cleaned_accepted_loans.rename(columns = {'term': 'term_months'}, inplace = True)\n",
    "num_cols[3] = 'term_months'\n",
    "cleaned_accepted_loans['term_months'] = cleaned_accepted_loans['term_months'].str.replace(\" months\", \"\")\n",
    "cleaned_accepted_loans['term_months'] = cleaned_accepted_loans['term_months'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30848913",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_accepted_loans.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find any na rows and fill them as needed\n",
    "for rows in num_cols:\n",
    "    cleaned_accepted_loans.loc[:, rows] = cleaned_accepted_loans[rows].fillna(cleaned_accepted_loans[rows].median())\n",
    "\n",
    "cleaned_accepted_loans.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a sample of the cleaned up \n",
    "sampled_accepted_loans = cleaned_accepted_loans.sample(200000, random_state = 821)\n",
    "sampled_accepted_loans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097496c4",
   "metadata": {},
   "source": [
    "**Clean Rejected Loan Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "639207ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Amount Requested               0\n",
       "Application Date               0\n",
       "Loan Title                  1305\n",
       "Risk_Score              18497630\n",
       "Debt-To-Income Ratio           0\n",
       "Zip Code                     293\n",
       "State                         22\n",
       "Employment Length         951355\n",
       "Policy Code                  918\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rejected_loans.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fabb8071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amount Requested', 'Application Date', 'Loan Title', 'Debt-To-Income Ratio']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Amount Requested        float64\n",
       "Application Date         object\n",
       "Loan Title               object\n",
       "Debt-To-Income Ratio     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop unneeded columns \n",
    "raw_rejected_loans = raw_rejected_loans.drop(columns=['Risk_Score', 'Zip Code', 'State', 'Policy Code', 'Employment Length'])\n",
    "rl_cols = list(raw_rejected_loans.columns)\n",
    "print(rl_cols)\n",
    "\n",
    "raw_rejected_loans.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "016f9677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt-To-Income Ratio\n",
       "100         1362556\n",
       "-1          1203063\n",
       "0           1045102\n",
       "9999          76984\n",
       "1.2           32659\n",
       "             ...   \n",
       "44805.67          1\n",
       "2602.53           1\n",
       "73243             1\n",
       "833.25            1\n",
       "28475             1\n",
       "Name: count, Length: 126145, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rejected_loans['Debt-To-Income Ratio'] = raw_rejected_loans['Debt-To-Income Ratio'].str.replace('%', '')\n",
    "raw_rejected_loans['Debt-To-Income Ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a01b78c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Debt-To-Income Ratio\n",
       "100.000000      1362556\n",
       "143.340051      1203063\n",
       "0.000000        1045102\n",
       "9999.000000       76984\n",
       "1.200000          32659\n",
       "                 ...   \n",
       "44805.670000          1\n",
       "2602.530000           1\n",
       "73243.000000          1\n",
       "833.250000            1\n",
       "28475.000000          1\n",
       "Name: count, Length: 126145, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fix any negative dti ratios\n",
    "raw_rejected_loans['Debt-To-Income Ratio'] = raw_rejected_loans['Debt-To-Income Ratio'].astype('float64')\n",
    "raw_rejected_loans.loc[raw_rejected_loans['Debt-To-Income Ratio'] < 0, 'Debt-To-Income Ratio'] = raw_rejected_loans['Debt-To-Income Ratio'].mean()\n",
    "raw_rejected_loans['Debt-To-Income Ratio'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40d4c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the Loan Title data\n",
    "raw_rejected_loans['Loan Title'] = (\n",
    "    raw_rejected_loans['Loan Title'].astype('string').str.lower()\n",
    "    .str.replace(r'[^a-z\\s]', ' ', regex = True)\n",
    "    .str.replace(r'\\s+', ' ', regex = True).str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "507e9293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan Title\n",
       "debt consolidation         12322066\n",
       "other                       4698761\n",
       "credit card refinancing     2298378\n",
       "credit card                 1364140\n",
       "home improvement            1190977\n",
       "                             ...   \n",
       "smmoore                           1\n",
       "thad                              1\n",
       "dougie                            1\n",
       "freeup                            1\n",
       "pay off debt and irs              1\n",
       "Name: count, Length: 60730, dtype: Int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rejected_loans['Loan Title'].fillna(raw_rejected_loans['Loan Title'].value_counts().reset_index().iat[0,0])\n",
    "raw_rejected_loans['Loan Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75597866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan Title\n",
       "debt_consolidation    12350757\n",
       "other                  9917873\n",
       "credit_card            3672642\n",
       "major_purchase          957587\n",
       "medical                 749676\n",
       "home_improvement           206\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_map(text):\n",
    "    \"\"\"\n",
    "    Function to normalize the loan reason column in rejected dataframe\n",
    "    \"\"\"\n",
    "    if pd.isna(text): text = '' \n",
    "    \n",
    "    if any (word in text for word in ['debt', 'consol']):\n",
    "        return 'debt_consolidation'\n",
    "    if any (word in text for word in ['cc', 'credit card']):\n",
    "        return 'credit_card'\n",
    "    if any (word in text for word in ['construction', 'remodeling', 'drywall']):\n",
    "        return 'home_improvement'\n",
    "    if any (word in text for word in ['major purchase', 'big buy']):\n",
    "        return 'major_purchase'\n",
    "    if any (word in text for word in ['medical', 'hospital', 'health', 'medical bill']):\n",
    "        return 'medical' \n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "raw_rejected_loans['Loan Title'] = raw_rejected_loans['Loan Title'].apply(word_map)\n",
    "\n",
    "raw_rejected_loans['Loan Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix any missing values in the rejection loans\n",
    "for rows in rl_cols:\n",
    "    #fix the rows that are of float type\n",
    "    if cleaned_rejected_loans[rows].dtypes == 'float64':\n",
    "        print(f\"replacing {rows} with median float\")\n",
    "        cleaned_rejected_loans.loc[:, rows] = cleaned_rejected_loans[rows].fillna(cleaned_rejected_loans[rows].median())\n",
    "    else:\n",
    "        #get the highest repeated string and replace N/A's with that string\n",
    "        print(f\"replacing {rows} na's with most repeated string\")\n",
    "        replacement_string = cleaned_rejected_loans[rows].value_counts().reset_index().at[0,rows]\n",
    "        cleaned_rejected_loans.loc[:, rows] = cleaned_rejected_loans[rows].fillna(replacement_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b4f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_rejected_loans.isna().sum()\n",
    "print(len(cleaned_rejected_loans))\n",
    "\n",
    "cleaned_rejected_loans.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get csv of accepted loans from 2023 HMDA\n",
    "import requests\n",
    "try:\n",
    "    #response = requests.get(\"https://ffiec.cfpb.gov/v2/data-browser-api/view/nationwide/csv?years=2023&actions_taken=1&loan_purpose=1\")\n",
    "    accepted_response = requests.get(\"https://files.ffiec.cfpb.gov/data-browser/datasets/2023/filtered-queries/one-year/a5a77b5e9528ccb95aae0dc60cea9d70.csv\", stream= True)\n",
    "    accepted_response.raise_for_status()\n",
    "except requests.HTTPError as e:\n",
    "    print(f\"Error getting HDMI data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71accde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning response into csv\n",
    "import io\n",
    "import csv\n",
    "raw_string = accepted_response.text\n",
    "split_string = raw_string.split('\\n')\n",
    "#write to a csv in the training data folder\n",
    "string_columns = split_string[0].split(',')\n",
    "string_data = [rows.split(',') for rows in split_string[1:]]\n",
    "\n",
    "hdma_path = DATA / 'hdma_accepted_raw.csv'\n",
    "\n",
    "with open(hdma_path, \"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(string_columns)\n",
    "    csv_writer.writerows(string_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import csv\n",
    "hdma_path = DATA / 'hdma_accepted_raw.csv'\n",
    "space_saver = pd.read_csv(hdma_path, low_memory= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7d6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdma_accepted_parquet = DATA / 'hdma_accepted_raw.parquet.gzip'\n",
    "#space_saver.to_parquet(hdma_accepted_parquet)\n",
    "for columns in space_saver.columns:\n",
    "    if space_saver[columns].dtype == 'object':\n",
    "        print('object')\n",
    "        space_saver[columns] = space_saver[columns].astype('string')\n",
    "    else:\n",
    "        print(space_saver[columns].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce063ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns that do not affect model predictions in any meaningful way. dropped in order to save space when uploading to repository\n",
    "drop_cols = [\n",
    "    'tract_population', 'tract_minority_population_percent', 'ffiec_msa_md_median_family_income', 'tract_to_msa_income_percentage',\n",
    "    'tract_owner_occupied_units', 'tract_one_to_four_family_homes', 'tract_median_age_of_housing_units', 'aus-1', 'aus-2', 'aus-3', 'aus-4',\n",
    "    'aus-5', 'applicant_ethnicity-1', 'applicant_ethnicity-2', 'applicant_ethnicity-3', 'applicant_ethnicity-4', 'applicant_ethnicity-5',\n",
    "    'co-applicant_ethnicity-1', 'co-applicant_ethnicity-2', 'co-applicant_ethnicity-3', 'co-applicant_ethnicity-4', 'co-applicant_ethnicity-5',\n",
    "    'applicant_ethnicity_observed', 'co-applicant_ethnicity_observed', 'applicant_race-1', 'applicant_race-2', 'applicant_race-3', 'applicant_race-4',\n",
    "    'applicant_race-5', 'co-applicant_race-1', 'co-applicant_race-2', 'co-applicant_race-3', 'co-applicant_race-4', 'co-applicant_race-5',\n",
    "    'applicant_race_observed', 'co-applicant_race_observed', 'applicant_sex', 'co-applicant_sex', 'applicant_sex_observed', 'co-applicant_sex_observed',\n",
    "    'applicant_age', 'co-applicant_age', 'applicant_age_above_62', 'co-applicant_age_above_62'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3e39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_saver.drop(columns = drop_cols).to_parquet(hdma_accepted_parquet, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered = pd.read_parquet(hdma_accepted_parquet, columns=temp_num_cols + temp_text_cols)\n",
    "\n",
    "#print(temp_num_cols + temp_text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd7216",
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164f9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_index = []\n",
    "\n",
    "#get the column numbers needed\n",
    "for columns in temp_num_cols:\n",
    "    remove_index.append(string_columns.index(columns))\n",
    "\n",
    "for columns in temp_text_cols:\n",
    "    remove_index.append(string_columns.index(columns))\n",
    "\n",
    "print(remove_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13815a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized_cols = [row for row in string_columns if string_columns.index(row) in remove_index]\n",
    "finalized_text = [row for row in string_data if string_data.index(row) in remove_index]\n",
    "print((finalized_cols))\n",
    "print(len(string_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_list = [i for i in range(0,100) if i not in remove_index]\n",
    "print(temp_list)\n",
    "split_string.clear()\n",
    "print(len(temp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(string_columns)\n",
    "print(string_data[0])\n",
    "hmda_accepted = pd.DataFrame(string_data, columns=string_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e58e0f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnum_cols = [\\n    \"id\", \"loan_amnt\", \"funded_amnt\", \"term\", \"int_rate\", \"installment\", \"annual_inc\",\\n    \"dti\", \"delinq_2yrs\", \"fico_range_low\", \"fico_range_high\", \"inq_last_6mths\",\\n    \"open_acc\", \"revol_bal\", \"revol_util\", \"total_acc\", \"pub_rec_bankruptcies\"\\n]\\n\\ntext_cols = [\\n    \"home_ownership\", \"loan_status\", \"purpose\", \"application_type\", \"verification_status\"\\n]\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://ffiec.cfpb.gov/documentation/publications/loan-level-datasets/lar-data-fields#loan_amount\n",
    "temp_num_cols = [\n",
    "    'activity_year', 'action_taken', 'preapproval', 'loan_purpose', 'loan_amount', 'loan_to_value_ratio',\n",
    "    'loan_term', 'income', 'debt_to_income_ratio'\n",
    "    ]\n",
    "temp_text_cols = [\n",
    "    'derived_loan_product_type', 'applicant_credit_score_type', 'co-applicant_credit_score_type', 'denial_reason-1'\n",
    "    ]\n",
    "\n",
    "\"\"\"\n",
    "num_cols = [\n",
    "    \"id\", \"loan_amnt\", \"funded_amnt\", \"term\", \"int_rate\", \"installment\", \"annual_inc\",\n",
    "    \"dti\", \"delinq_2yrs\", \"fico_range_low\", \"fico_range_high\", \"inq_last_6mths\",\n",
    "    \"open_acc\", \"revol_bal\", \"revol_util\", \"total_acc\", \"pub_rec_bankruptcies\"\n",
    "]\n",
    "\n",
    "text_cols = [\n",
    "    \"home_ownership\", \"loan_status\", \"purpose\", \"application_type\", \"verification_status\"\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmda_accepted.iloc[0:5,20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c7ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmda_accepted = hmda_accepted[temp_num_cols + temp_text_cols]\n",
    "hmda_accepted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmda_accepted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f591ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get csv of rejected loans from 2023 HMDA\n",
    "import requests\n",
    "try:\n",
    "    rejected_response = requests.get(\"https://ffiec.cfpb.gov/v2/data-browser-api/view/nationwide/csv?years=2023&actions_taken=3&loan_purpose=1\")\n",
    "    rejected_response.raise_for_status()\n",
    "except requests.HTTPError as e:\n",
    "    print(f\"Error getting HDMI data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47866d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_string = rejected_response.text\n",
    "split_string = rejected_string.split('\\n')\n",
    "#write to a csv in the training data folder\n",
    "rejected_columns = split_string[0].split(',')\n",
    "rejected_data = [rows.split(',') for rows in split_string[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e219b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(rejected_columns))\n",
    "#print(rejected_data[0])\n",
    "hdma_rejected_path = DATA / 'hdma_rejected_raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write raw data to unique csv\n",
    "import csv\n",
    "with open(hdma_rejected_path, \"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(rejected_columns)\n",
    "    csv_writer.writerows(rejected_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae695425",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\Saul\\\\Desktop\\\\Credit Risk Assessment\\\\credit-risk-assessment\\\\ETL\\\\training_data\\\\hdma_rejected_raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#Temporarily read csv, drop unneeded columns, and parquet the file to save space\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m rejected_temp = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdma_rejected_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m hdma_rejected_parquet = DATA / \u001b[33m'\u001b[39m\u001b[33mhdma_rejected_raw.parquet.gzip\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#space_saver.to_parquet(hdma_accepted_parquet)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Saul\\Desktop\\Credit Risk Assessment\\credit-risk-assessment\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Saul\\\\Desktop\\\\Credit Risk Assessment\\\\credit-risk-assessment\\\\ETL\\\\training_data\\\\hdma_rejected_raw.csv'"
     ]
    }
   ],
   "source": [
    "#Temporarily read csv, drop unneeded columns, and parquet the file to save space\n",
    "rejected_temp = pd.read_csv(hdma_rejected_path, low_memory= False)\n",
    "\n",
    "hdma_rejected_parquet = DATA / 'hdma_rejected_raw.parquet.gzip'\n",
    "#space_saver.to_parquet(hdma_accepted_parquet)\n",
    "for columns in rejected_temp.columns:\n",
    "    if rejected_temp[columns].dtype == 'object':\n",
    "        print('object')\n",
    "        rejected_temp[columns] = rejected_temp[columns].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc90c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_temp.drop(columns = drop_cols).to_parquet(hdma_rejected_parquet, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74efb7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdma_accepted_parquet = DATA / 'hdma_accepted_raw.parquet.gzip'\n",
    "hdma_rejected_parquet = DATA / 'hdma_rejected_raw.parquet.gzip'\n",
    "accepted_recovered = pd.read_parquet(hdma_accepted_parquet, columns=temp_num_cols + temp_text_cols)\n",
    "rejected_recovered = pd.read_parquet(hdma_rejected_parquet, columns=temp_num_cols + temp_text_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347c1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_recovered.isna().sum()\n",
    "accepted_recovered.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16a85d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_year</th>\n",
       "      <th>action_taken</th>\n",
       "      <th>preapproval</th>\n",
       "      <th>loan_purpose</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_to_value_ratio</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>income</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>derived_loan_product_type</th>\n",
       "      <th>applicant_credit_score_type</th>\n",
       "      <th>co-applicant_credit_score_type</th>\n",
       "      <th>denial_reason-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>545000.0</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>360</td>\n",
       "      <td>110.0</td>\n",
       "      <td>50%-60%</td>\n",
       "      <td>Conventional:First Lien</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>98.97400</td>\n",
       "      <td>360</td>\n",
       "      <td>65.0</td>\n",
       "      <td>50%-60%</td>\n",
       "      <td>FHA:First Lien</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255000.0</td>\n",
       "      <td>96.50000</td>\n",
       "      <td>360</td>\n",
       "      <td>39.0</td>\n",
       "      <td>&gt;60%</td>\n",
       "      <td>FHA:First Lien</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>360</td>\n",
       "      <td>85.0</td>\n",
       "      <td>&gt;60%</td>\n",
       "      <td>Conventional:First Lien</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>425000.0</td>\n",
       "      <td>78.87900</td>\n",
       "      <td>360</td>\n",
       "      <td>158.0</td>\n",
       "      <td>30%-&lt;36%</td>\n",
       "      <td>FHA:First Lien</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>215000.0</td>\n",
       "      <td>84.70600</td>\n",
       "      <td>360</td>\n",
       "      <td>92.0</td>\n",
       "      <td>&gt;60%</td>\n",
       "      <td>VA:First Lien</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>245000.0</td>\n",
       "      <td>96.50000</td>\n",
       "      <td>360</td>\n",
       "      <td>48.0</td>\n",
       "      <td>50%-60%</td>\n",
       "      <td>FHA:First Lien</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>565000.0</td>\n",
       "      <td>76.08700</td>\n",
       "      <td>360</td>\n",
       "      <td>134.0</td>\n",
       "      <td>50%-60%</td>\n",
       "      <td>FHA:First Lien</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>415000.0</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>360</td>\n",
       "      <td>177.0</td>\n",
       "      <td>50%-60%</td>\n",
       "      <td>Conventional:First Lien</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>365000.0</td>\n",
       "      <td>40.78200</td>\n",
       "      <td>360</td>\n",
       "      <td>47.0</td>\n",
       "      <td>&gt;60%</td>\n",
       "      <td>Conventional:First Lien</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_year  action_taken  preapproval  loan_purpose  loan_amount  \\\n",
       "0         2023.0           3.0          2.0           1.0     545000.0   \n",
       "1         2023.0           3.0          2.0           1.0     315000.0   \n",
       "2         2023.0           3.0          2.0           1.0     255000.0   \n",
       "3         2023.0           3.0          2.0           1.0     425000.0   \n",
       "4         2023.0           3.0          2.0          32.0     425000.0   \n",
       "5         2023.0           3.0          2.0          32.0     215000.0   \n",
       "6         2023.0           3.0          2.0           1.0     245000.0   \n",
       "7         2023.0           3.0          2.0          32.0     565000.0   \n",
       "8         2023.0           3.0          2.0           1.0     415000.0   \n",
       "9         2023.0           3.0          2.0          32.0     365000.0   \n",
       "\n",
       "  loan_to_value_ratio loan_term  income debt_to_income_ratio  \\\n",
       "0            80.00000       360   110.0              50%-60%   \n",
       "1            98.97400       360    65.0              50%-60%   \n",
       "2            96.50000       360    39.0                 >60%   \n",
       "3            90.00000       360    85.0                 >60%   \n",
       "4            78.87900       360   158.0             30%-<36%   \n",
       "5            84.70600       360    92.0                 >60%   \n",
       "6            96.50000       360    48.0              50%-60%   \n",
       "7            76.08700       360   134.0              50%-60%   \n",
       "8            75.00000       360   177.0              50%-60%   \n",
       "9            40.78200       360    47.0                 >60%   \n",
       "\n",
       "  derived_loan_product_type  applicant_credit_score_type  \\\n",
       "0   Conventional:First Lien                          2.0   \n",
       "1            FHA:First Lien                          3.0   \n",
       "2            FHA:First Lien                          2.0   \n",
       "3   Conventional:First Lien                          2.0   \n",
       "4            FHA:First Lien                          1.0   \n",
       "5             VA:First Lien                          3.0   \n",
       "6            FHA:First Lien                          1.0   \n",
       "7            FHA:First Lien                          1.0   \n",
       "8   Conventional:First Lien                          3.0   \n",
       "9   Conventional:First Lien                          2.0   \n",
       "\n",
       "   co-applicant_credit_score_type  denial_reason-1  \n",
       "0                             9.0              1.0  \n",
       "1                             9.0              4.0  \n",
       "2                            10.0              1.0  \n",
       "3                             9.0              1.0  \n",
       "4                             9.0              1.0  \n",
       "5                            10.0              1.0  \n",
       "6                            10.0              1.0  \n",
       "7                             9.0              3.0  \n",
       "8                             9.0              1.0  \n",
       "9                            10.0              1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rejected_recovered.isna().sum()\n",
    "rejected_recovered.head(10)\n",
    "#rejected_recovered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52ae547a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   denial_reason-1   count\n",
      "0              1.0  690467\n",
      "1              3.0  565385\n",
      "2              4.0  263717\n",
      "3              7.0  198298\n",
      "4              9.0  156939\n",
      "5              6.0   74591\n",
      "6              5.0   38532\n",
      "7           1111.0   25720\n",
      "8              2.0   23046\n",
      "9              8.0     399\n"
     ]
    }
   ],
   "source": [
    "test_name = 'denial_reason-1'\n",
    "print(rejected_recovered[test_name].value_counts().reset_index())\n",
    "#print(rejected_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "int_values = [\n",
    "    'activity_year', 'action_taken', 'preapproval', 'loan_purpose', 'loan_amount', 'loan_term', 'applicant_credit_score_type',\n",
    "    'co-applicant_credit_score_type', 'denial_reason-1'\n",
    "]\n",
    "\n",
    "float_values = [\n",
    "    'loan_to_value_ratio', 'income', 'debt_to_income_ratio'\n",
    "]\n",
    "\n",
    "string_values = [\n",
    "    'derived_loan_product_type'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert any ranges into the middle of that range, or leave it at that range if its too broad\n",
    "test_name = 'debt_to_income_ratio'\n",
    "ranges = rejected_recovered[test_name].value_counts().reset_index()\n",
    "\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace(\">60%\", 60)\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace(\"50%-60%\", 55)\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace(\"20%-<30%\", (29+20)/2)\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace(\"30%-<36%\", (35+30)/2)\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace(\"<20%\", 20)\n",
    "\n",
    "rejected_recovered[test_name].value_counts().reset_index()\n",
    "\n",
    "#rejected_recovered[column] = rejected_recovered[column].astype('float64', errors=\"ignore\")\n",
    "\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace('Exempt', rejected_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "rejected_recovered[test_name].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = 'loan_term'\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace('Exempt', rejected_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "rejected_recovered[test_name].value_counts().reset_index()\n",
    "print(len(rejected_recovered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311e4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = 'income'\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace('Exempt', rejected_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "rejected_recovered[test_name].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25550c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = 'loan_to_value_ratio'\n",
    "#fix any rows that have exempt\n",
    "\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace('Exempt', rejected_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "rejected_recovered[test_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2b1d7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = 'denial_reason-1'\n",
    "\n",
    "rejected_recovered[test_name] = rejected_recovered[test_name].replace(1111, rejected_recovered[test_name].value_counts().reset_index().iat[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2439054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "print(type(rejected_recovered[test_name].value_counts().get('Exempt', default=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817fd742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up dataframe and turn it into proper typings\n",
    "for column in int_values:\n",
    "    print(f\"changing column: {column}\")\n",
    "    rejected_recovered[column] = rejected_recovered[column].fillna(rejected_recovered[column].value_counts().reset_index().iat[0, 0])\n",
    "    try:\n",
    "        rejected_recovered[column] = rejected_recovered[column].astype('int32')\n",
    "    except Exception as e:\n",
    "        print(f\"skipping int conversion: {column}\") \n",
    "        print(f\"reason: {e}\")\n",
    "        continue  \n",
    "    \n",
    "\n",
    "for column in float_values:\n",
    "    print(f\"converting float: {column}\")\n",
    "    rejected_recovered[column] = rejected_recovered[column].fillna(rejected_recovered[column].value_counts().reset_index().iat[0, 0])   \n",
    "    try:\n",
    "        rejected_recovered[column] = rejected_recovered[column].astype('float64')\n",
    "    except Exception as e:\n",
    "        print(f\"skipping float conversion: {column}\")\n",
    "        print(f\"reason: {e}\")\n",
    "\n",
    "for column in string_values:\n",
    "    rejected_recovered[column] = rejected_recovered[column].fillna(rejected_recovered[column].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "rejected_recovered.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cbf26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "for column in rejected_recovered.columns:\n",
    "    if rejected_recovered[column].dtype == 'float64':\n",
    "\"\"\"\n",
    "\n",
    "rejected_recovered.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers from rejected df based on loan amount\n",
    "rejected_recovered\n",
    "\n",
    "\"\"\"\n",
    "int_values = [\n",
    "    'activity_year', 'action_taken', 'preapproval', 'loan_purpose', 'loan_amount', 'loan_term', 'applicant_credit_score_type',\n",
    "    'co-applicant_credit_score_type', 'denial_reason-1'\n",
    "]\n",
    "\n",
    "float_values = [\n",
    "    'loan_to_value_ratio', 'income', 'debt_to_income_ratio'\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "loan_std = rejected_recovered['loan_amount'].std()\n",
    "loan_mean = rejected_recovered['loan_amount'].mean()\n",
    "print(loan_std)\n",
    "print(loan_mean)\n",
    "temp_z_data = rejected_recovered.copy()\n",
    "temp_z_data['z_loan'] = ((rejected_recovered['loan_amount'] - loan_mean) / loan_std)\n",
    "threshold = 3\n",
    "\n",
    "#remove based on threshold\n",
    "no_outliers_rejected = temp_z_data[(temp_z_data['z_loan'].abs()) <= threshold].drop(columns=['z_loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outliers_rejected['loan_amount'].value_counts().reset_index()\n",
    "print(len(no_outliers_rejected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788a2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up accepted hdma loan (repeat of the rejected clean up process)\n",
    "#Convert any ranges into the middle of that range, or leave it at that range if its too broad\n",
    "test_name = 'debt_to_income_ratio'\n",
    "ranges = accepted_recovered[test_name].value_counts().reset_index()\n",
    "\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace(\">60%\", 60)\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace(\"50%-60%\", 55)\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace(\"20%-<30%\", (29+20)/2)\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace(\"30%-<36%\", (35+30)/2)\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace(\"<20%\", 20)\n",
    "\n",
    "accepted_recovered[test_name].value_counts().reset_index()\n",
    "\n",
    "#accepted_recovered[column] = accepted_recovered[column].astype('float64', errors=\"ignore\")\n",
    "\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace('Exempt', accepted_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "accepted_recovered[test_name].value_counts().reset_index()\n",
    "\n",
    "test_name = 'loan_term'\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace('Exempt', accepted_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "accepted_recovered[test_name].value_counts().reset_index()\n",
    "print(len(accepted_recovered))\n",
    "\n",
    "test_name = 'income'\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace('Exempt', accepted_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "accepted_recovered[test_name].value_counts()\n",
    "\n",
    "test_name = 'loan_to_value_ratio'\n",
    "#fix any rows that have exempt\n",
    "\n",
    "accepted_recovered[test_name] = accepted_recovered[test_name].replace('Exempt', accepted_recovered[test_name].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "accepted_recovered[test_name]\n",
    "\n",
    "#clean up dataframe and turn it into proper typings\n",
    "for column in int_values:\n",
    "    print(f\"changing column: {column}\")\n",
    "    accepted_recovered[column] = accepted_recovered[column].fillna(accepted_recovered[column].value_counts().reset_index().iat[0, 0])\n",
    "    try:\n",
    "        accepted_recovered[column] = accepted_recovered[column].astype('int32')\n",
    "    except Exception as e:\n",
    "        print(f\"skipping int conversion: {column}\") \n",
    "        print(f\"reason: {e}\")\n",
    "        continue  \n",
    "    \n",
    "\n",
    "for column in float_values:\n",
    "    print(f\"converting float: {column}\")\n",
    "    accepted_recovered[column] = accepted_recovered[column].fillna(accepted_recovered[column].value_counts().reset_index().iat[0, 0])   \n",
    "    try:\n",
    "        accepted_recovered[column] = accepted_recovered[column].astype('float64')\n",
    "    except Exception as e:\n",
    "        print(f\"skipping float conversion: {column}\")\n",
    "        print(f\"reason: {e}\")\n",
    "\n",
    "for column in string_values:\n",
    "    accepted_recovered[column] = accepted_recovered[column].fillna(accepted_recovered[column].value_counts().reset_index().iat[0, 0])\n",
    "\n",
    "loan_std = accepted_recovered['loan_amount'].std()\n",
    "loan_mean = accepted_recovered['loan_amount'].mean()\n",
    "print(loan_std)\n",
    "print(loan_mean)\n",
    "temp_z_data = accepted_recovered.copy()\n",
    "temp_z_data['z_loan'] = ((accepted_recovered['loan_amount'] - loan_mean) / loan_std)\n",
    "threshold = 3\n",
    "\n",
    "#remove based on threshold\n",
    "no_outliers_accepted = temp_z_data[(temp_z_data['z_loan'].abs()) <= threshold].drop(columns=['z_loan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete_large_files()\n",
    "\n",
    "no_outliers_accepted.head(10)\n",
    "no_outliers_accepted.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
